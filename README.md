# deep-learning-from-scratch
Deep Learning from Scratch  This project implements a neural network in Python from scratch, using the MNIST dataset to classify images of the digit '5'. It includes custom functions for forward propagation, cost computation, and backpropagation. Visualizations of training metrics are provided, along with a comprehensive report and dataset details.

This project is centered around building a Deep Learning model from the ground up, without using high-level libraries like Sequential or Dense. The focus was on understanding and manually implementing key components of a neural network, including forward propagation, cost computation, and back propagation, in Python.

The project involves:

Forward Propagation: A custom function that passes data through the network’s layers, computing activations step by step.
Cost Computation: A function to calculate the error (cost) between the predicted and actual outcomes, providing feedback on model performance.
Back Propagation: A manually implemented function for adjusting the weights and biases by computing the gradients, allowing the network to learn through optimization techniques.
A suitable dataset was chosen, and the data was normalized before training. Key visualizations created during the project include:

Scatter Plot: A visual representation of the dataset for better understanding and exploratory data analysis.
Cost vs. Epochs Plot: A graph demonstrating how the model’s performance improves (or stabilizes) over time with training.
The report was created using Google Docs, detailing the project’s objectives, approach, methodology, and results. It provides a clear, concise explanation of the neural network implementation, accompanied by visual results and analysis of the training process.

Technologies Used:

Python for deep learning model implementation
Matplotlib for visualizations
Google Docs for documentation
